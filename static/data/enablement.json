{
  "meta": {
    "version": "1.1.0",
    "audience": [
      "engineering managers",
      "tech leads",
      "staff/IC engineers hiring for AI/coding roles",
      "product leadership (technical-leaning)"
    ],
    "tone": "direct, practical, low-fluff",
    "canonical_resume_path": "/resume",
    "principle": "Effectiveness > output. Effectiveness = rate of progress toward goals.",
    "contact_mode": "email-first; contact for quote or to hire"
  },

  "hero": {
    "title": "AI Enablement that Drives Effectiveness",
    "subtitle": "Ship faster and safer, with workflows your team will actually use.",
    "primary_cta": { "label": "Email me", "href": "mailto:you@example.com" },
    "secondary_cta": { "label": "See approach", "href": "#process" },
    "notes": "Resume remains minimal at /resume"
  },

  "value_props": [
    {
      "id": "effectiveness-first",
      "title": "Effectiveness first",
      "bullets": [
        "AI can increase raw output, but effectiveness = progress toward goals.",
        "We design workflows, not just prompts, so gains stick."
      ]
    },
    {
      "id": "legit-wins",
      "title": "Legitimate wins early",
      "bullets": [
        "People adopt AI when they feel a real speed-up in *their* work.",
        "We minimize time-to-first-win and time-to-productivity."
      ]
    },
    {
      "id": "friction-reduction",
      "title": "Friction reduction",
      "bullets": [
        "Standard tools, defaults, setup guides, and exemplars.",
        "Workshops and 1:1 pairing to remove blockers quickly."
      ]
    },
    {
      "id": "security-grounded",
      "title": "Security-grounded",
      "bullets": [
        "Risk profiles differ; we right-size controls (ZDR, sandboxing, allowlists).",
        "Agentic safety and prompt-injection defenses from day one."
      ]
    },
    {
      "id": "future-advantage",
      "title": "Advantage compounds",
      "bullets": [
        "Skills built now compound as models improve.",
        "Even if gains are modest today, you'll be ahead when capabilities jump."
      ]
    }
  ],

  "sections": [
    {
      "id": "what-i-do",
      "type": "cards",
      "title": "How I Help",
      "cards": [
        {
          "title": "Workflow & Tooling Enablement",
          "body": "Deeply understand your organization's goals and jobs-to-be-done, pick high-leverage workflows, and fit AI into daily routines.",
          "deliverables": ["Workflow maps", "Tool choices & defaults", "Starter prompts/snippets", "Playbooks"]
        },
        {
          "title": "Engineering Acceleration",
          "body": "Best practices for AI coding: codegen, review, refactors, tests, and safe agentic automation.",
          "deliverables": ["Personalized AGENTS.md", "Codebase-specific rules", "IDE setup (e.g., AI pair tools)"]
        },
        {
          "title": "Security, Risk & Governance",
          "body": "Align on risk profile, data exposure limits, and safe tool use (ZDR, secrets, sandbox).",
          "deliverables": ["Risk profile & policy", "Agent permissions model", "Incident playbook"]
        },
        {
          "title": "Training & Adoption",
          "body": "Group workshops, role-based coaching, training enthusiasts as coaches.",
          "deliverables": ["Workshops", "1:1 pairing", "Role guides", "Usage & outcome metrics"]
        }
      ]
    },

    {
      "id": "effectiveness",
      "type": "text",
      "title": "Effectiveness > Output",
      "body": [
        "AI can raise output (e.g., more code), but that doesn't guarantee progress on the right things.",
        "Effectiveness is your **rate of progress toward goals**. We design prompts, tools, and workflows so quality, reliability, and alignment improve along with speed."
      ]
    },

    {
      "id": "codebase-context",
      "type": "bullets",
      "title": "Your Codebase Is the Most Important Context",
      "bullets": [
        "Agents mirror your patterns: clean architecture and consistent practices produce better AI outputs.",
        "LLMs have limited effective context—avoid polluting it. Smaller, focused files help models read only what's needed.",
        "Prefer 1,000 files × 100 lines over 100 files × 1,000 lines when feasible.",
        "Clear READMEs, best practices, and explicit rules dramatically reduce prompt overhead; unwritten, inconsistently followed rules leak into the results."
      ]
    },

    {
      "id": "learning-curve",
      "type": "bullets",
      "title": "Learning Curve: Slower Before Faster",
      "bullets": [
        "New workflows create temporary drag—plan for it.",
        "Design for quick wins and practice reps so teams cross the dip fast.",
        "Measure time-to-first-win and time-to-productivity explicitly."
      ]
    },

    {
      "id": "adoption-curve",
      "type": "bullets",
      "title": "Why Adopt Now",
      "bullets": [
        "We can't guarantee exponential improvement, but a reasonable baseline is that models get somewhat better over time.",
        "Skills built today create a **compounding advantage** when capabilities step-change.",
        "Even skeptics can benefit from targeted, low-risk wins while policies mature."
      ]
    },

    {
      "id": "prompting-best-practices",
      "type": "accordion",
      "title": "Best Practices: Prompting, Planning & Agents",
      "items": [
        {
          "label": "Set the AI up to succeed",
          "content": [
            "Imagine handing the task to a junior/intermediate with no context—what would they need?",
            "Include purpose, constraints, acceptance criteria, examples, and the target audience."
          ]
        },
        {
          "label": "Right-size the instruction detail",
          "content": [
            "Simple tasks can succeed with lightweight prompts.",
            "Complex tasks need detailed specs—learning the bar is a skill."
          ]
        },
        {
          "label": "Plan → Clarify → Execute",
          "content": [
            "Ask the model to propose a plan, list assumptions/risks, and ask clarifying questions.",
            "For large efforts: generate a plan → break into tickets → produce technical designs per ticket."
          ]
        },
        {
          "label": "Long-lived instructions (AGENTS.md)",
          "content": [
            "Maintain durable, codebase-specific rules and conventions (naming, architecture, security musts).",
            "Think: the parts you'd repeat in careful prompts almost every time—persist them so agents don't forget.",
            "Keep it versioned, reviewed, and discoverable next to the code (e.g., /AGENTS.md)."
          ]
        },
        {
          "label": "Ensure complete context & tools",
          "content": [
            "Give each session the documents, code, and tools it needs.",
            "If you use tool plugins or MCP-style connectors, make sure they're wired in each time."
          ]
        },
        {
          "label": "Tight feedback loops",
          "content": [
            "Iterate with small steps and checks (tests, linters, reviewers).",
            "Browser-use MCPs let agents see the results of their actions."
          ]
        }
      ]
    },

    {
      "id": "security",
      "type": "accordion",
      "title": "Security & Risk (Tradeoffs Are Real)",
      "intro": "Different orgs need different ceilings on AI augmentation. We choose controls that match your risk profile.",
      "items": [
        {
          "label": "Risk profile first",
          "content": [
            "If code exposure is unacceptable, your augmentation ceiling is lower; we prioritize on-device or ZDR paths and restrict tool scope."
          ]
        },
        {
          "label": "Zero-data-retention (ZDR) & secrets hygiene",
          "content": [
            "Prefer vendors/modes that don't retain prompts/outputs; block training on your data.",
            "Never paste secrets; rotate credentials; use ephemeral tokens."
          ]
        },
        {
          "label": "Agentic safety",
          "content": [
            "No \"skip-permissions\" for CLI or filesystem actions.",
            "Enforce dry-runs, allowlists, and human confirmation.",
            "Beware scripts that bundle destructive commands—review before execution."
          ]
        },
        {
          "label": "Prompt injection & external content",
          "content": [
            "Treat web/Docs/HTML as **untrusted** inputs; use content firewalls, allowlisted domains, and output filtering.",
            "Train users to recognize \"IGNORE PREVIOUS INSTRUCTIONS\"-style attacks."
          ]
        }
      ]
    },

    {
      "id": "reduce-friction",
      "type": "bullets",
      "title": "Reducing Friction to First Win",
      "bullets": [
        "Standardize on a default model and toolchain; publish setup guides.",
        "Provide prompt libraries, code snippets, and example repos.",
        "Offer workshops & 1:1 pairing—engineers often prefer hands-on pairing.",
        "For non-coders, provide a research assistant template with success examples.",
        "Listen first: gather pain points and moral concerns; tailor the plan."
      ]
    },

    {
      "id": "metrics-usage",
      "type": "bullets",
      "title": "Metrics & Usage (Avoid Goodhart's Law)",
      "bullets": [
        "Track usage volumes **and** patterns (model choice, CLI vs agent vs tab-completion).",
        "Review outcomes, not just counts—link to cycle time, review quality, and defect rates.",
        "Use metrics to inform decisions; don't turn them into targets that distort behavior."
      ]
    },

    {
      "id": "adoption-culture",
      "type": "text",
      "title": "Adoption & Culture",
      "body": [
        "Different objections need different responses: ethics vs speed vs quality.",
        "Your goal is organizational effectiveness—not AI for its own sake.",
        "Push too hard and you create resentment; instead, kindle excitement with real wins.",
        "A practical approach: ask everyone to try once, listen to feedback, keep reducing friction, and respect those who opt out."
      ]
    },

    {
      "id": "pitfalls",
      "type": "bullets",
      "title": "Pitfalls to Avoid",
      "bullets": [
        "80/20 trap: easy to get to 80%, hard to land the last 20%.",
        "Checking out with agents: don't fire-and-forget—run multiple tasks with checkpoints.",
        "AI mistakes differ from human mistakes: it may confidently take the wrong path or over-edit.",
        "Code quality hazards: deleting tests or violating best practices to \"make it pass.\"",
        "Using AI *instead of* thinking—flip it to **learn faster** with targeted questions."
      ]
    },

    {
      "id": "quick-wins",
      "type": "bullets",
      "title": "Good First Wins (Examples)",
      "bullets": [
        "Quickly understanding a codebase and its goals.",
        "Write tests from examples; then refine.",
        "Refactor small, mechanical code; add docstrings and type hints.",
        "Summarize RFCs/PRs; generate checklists from standards.",
        "Draft data pipelines or dbt models from schema + examples; you finalize.",
        "Generate skeletons for tickets, runbooks, and postmortems."
      ]
    },

    {
      "id": "process",
      "type": "process",
      "title": "Engagement Process",
      "steps": [
        "Discover: goals, constraints, risk profile, current stack.",
        "Find quick wins: pick 2–3 high-leverage workflows; define success criteria.",
        "Standards: prompting patterns, coding guardrails, security policies.",
        "Pilot & train: workshops + 1:1 pairing; measure outcomes.",
        "Scale: roll out playbooks; automate checks; ongoing evals."
      ]
    }
  ],

  "resources": [
    {
      "title": "Measuring AI ability to complete long tasks",
      "kind": "research",
      "url": "https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/",
      "notes": "On task time horizons and implications for automation timelines."
    },
    {
      "title": "OWASP: Top 10 for LLM Applications",
      "kind": "security",
      "url": "https://genai.owasp.org/llm-top-10/",
      "notes": "Key risks and mitigations (e.g., prompt injection)."
    },
    {
      "title": "Cursor Trust FAQ — Privacy Mode / Zero Data Retention",
      "kind": "vendor-docs",
      "url": "https://trust.cursor.com/faq",
      "notes": "Example of ZDR vendor language for enterprise posture."
    },
    {
      "title": "Model Context Protocol (MCP)",
      "kind": "protocol",
      "url": "https://docs.anthropic.com/en/docs/mcp",
      "notes": "Standard for connecting models to tools/data; ensures sessions have the right capabilities."
    }
  ],

  "cta": {
    "headline": "Curious if this would work for your team?",
    "subhead": "If these ideas resonate, let's talk about your context.",
    "actions": [
      { "label": "Email me", "href": "mailto:you@example.com" }
    ]
  }
}